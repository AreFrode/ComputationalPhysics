TITLE: Computational Physics:  Teach yourself C++
AUTHOR: Morten Hjorth-Jensen {copyright, 1999-present|CC BY-NC} at Department of Physics, University of Oslo & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University
DATE: today


===== Getting Started, compiling and linking first =====

The programming language C++ is a so-called "compiled language":"https://en.wikipedia.org/wiki/Compiled_language". For help on how to use C++, we recommend highly the "cpplus website":"http://www.cplusplus.com/". 


Assume we already have a program file, say _myprogram.cpp_. Note that C++ files have the extension _.cpp_.

Here we discuss first how to obtain an executable without using IDEs like "QT":"https://www.qt.io/" creator or other types of integrated development environments ("Visual Studio":"https://www.visualstudio.com/" or other, see "list":"https://sourceforge.net/directory/development/ide/" etc).


It means that you need to compile the program (translate the human-like instructions into machine code) and link the resulting compiled file (a so-called _object_ file) with the various libraries in order to obtain an executable file. 

In order to obtain an executable file for a C++ program, the following
instructions under Unix/Linux can be used ("similar instructions apply to windows-like environments using DOS":"https://msdn.microsoft.com/en-us/library/ms235639.aspx").

First you need to open a terminal on your Unix/Linux PC/laptop. You need also to have a C++ compiler installed. To check on Unix/Linux whether a c++ is installed or not type simply (in the terminal window)
!bc sys
which c++
!ec
If you get something like 
!bc 
Mortens-MacBook-Pro:~ hjensen$ which c++
/usr/bin/c++
!ec
you are ok. 
Then compile and link your program as
!bc sys
c++ -c -Wall myprogram.cpp
c++ -o myprogram.exe  myprogram.o
!ec
where the compiler is called through the command c++/g++. The compiler
option -Wall means that a warning is issued in case of non-standard
language. The executable file is in this case _myprogram.exe_. The option
`-c` is for compilation only, where the program is translated into machine code,
while the `-o` option links the produced object file _myprogram.o_ with other libraries 
and produces the executable _myprogram.exe_.

You can skip the first step by simply writing
!bc sys
c++ -o myprogram.exe  myprogram.cpp
!ec


Also, to speed up the code use compile options like (compiler flags will be dealt with later)

!bc sys
c++ -O3 -c -Wall myprogram.cpp
!ec


To run your program, simply write 
!bc sys
myprogram.exe
!ec
or if you wish to avoid creating executables which by accident have the same name as operating system commands (with sometime fatal consequences) write
!bc sys
./myprogram.exe
!ec
Here, using . denotes the current directory. Since you want to run a file in your current directory and that directory is not in your $PATH, you need the ./ bit to tell the shell where the executable is.



Under Linux/Unix it is often convenient to create a
so-called makefile, which is a script which includes possible
compiling commands.  By clicking on the link here you can see examples of "makefiles":"https://www.gnu.org/software/make/manual/make.html". 


If you name your file for _makefile_, simply type the command
_make_ and Linux/Unix executes all possible statements included in your makefile. 

When you use an IDE like Qt, it creates automatically something similar to a makefile for you and you don't need to hardcode the above statements. 




Our first program is the classic "Hello World":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/hellow.cpp".

Here we present the C++ version using _namespace_, see shortly below here for an explanation.
!bc cpppro
// A comment line begins like this in C++ programs
// Standard ANSI-C++ include files
#include <cstdlib> // atof function 
#include <iostream>   // input and output
#include <cmath>      // math functions
using namespace std;
int main (int argc, char* argv[])
{
  // convert the text argv[1] to double using atof:
  double r = atof(argv[1]);  // convert the text argv[1] to double
  double s = sin(r);
  cout << "Hello, World! sin(" << r << ") =" << s << endl;
  return 0;           // success execution of the program 
}
!ec

The compiler must see a declaration of a function before you can
call it (the compiler checks the argument and return types).
The declaration of library functions appears
in so-called ``header files'' that must be included in the program, as an example the following statement includes the so-called _Standard Library Functions_

!bc cppcod
   #include <cstdlib> // atof function 
!ec
We call three functions (atof, sin, cout)
and these are declared in three different header files. These declarations should come first. The _cout_ function is included in the _isostream_. In C++, input and output (I/O) operations  are performed by using so-called streams which a *stream of data* where a  stream is an object with properties that are defined by a class. Global objects are predefined for the standard I/O channels.   The _sin_ function is defined by the _cmath_ library and its header file and needs to be included. For those of you familiar with _Python_ this is similar to 
!bc pycod
from math import sin
!ec

"The main program is a function called main":"http://en.cppreference.com/w/cpp/language/return"
with a return value set to an integer, int (0 if success).
The operating system stores the return value,
and other programs/utilities can check whether
the execution was successful or not. The main program has thus to be declared as _int main()_ in standard C++. 
The command-line arguments are transferred to the main function through

!bc cppcod
   int main (int argc, char* argv[])
!ec

The command-line arguments are transferred to the main function through

!bc cppcod
   int main (int argc, char* argv[])
!ec
The integer _argc_ is the number  of command-line arguments (two in our case) while
_argv_ is a vector of strings containing the command-line arguments
with _argv[0]_ containing  the name of the program
and _argv[1]_, _argv[2]_, ... are the command-line args, i.e., the number of
arguments that are  inputs to the program.

We define floating point variables, see also below,
through the keywords _float_ for single precision real numbers and
_double_ for double precision real numbers. The function
_atof_ transforms a text string to a float, either single or double precision.
The _sine_ function is declared in _cmath_, a library which
is not automatically included and needs to be linked when computing
and producing the  executable file. Note that arrays in C++ begin by default with $0$. The first element is here _argv[0]_. 

A one-dimensional array like _argv_ can be defined statically or dynamically. To reserve space in memory statically means defining a variable of this type as
!bc cppcod
char argv[10]; 
!ec
which contains in this case ten elements. Each element has a specific address in memory, see the discussions below on pointers. We anticipate partly the discussion here by declaring a pointer variable and allocating memory dynamically. In C++ this is done as

!bc cppcod
char *argv;  // declaring first a pointer
argv = new char[10];   // Now reserving space for  ten elements in memory for a character variable (4 bytes or 32 bits).
!ec

For a floating point variable of  8 bytes or 64 bits we would declare a similar array as
!bc cppcod
double *argv;  // declaring first a pointer
argv = new double[10];   // Now reserving space for  ten elements in memory for a character variable (4 bytes or 32 bits).
!ec
In similar ways we can declare integer variable, single precisions floats etc.
We can write the above in one line as
!bc cppcod
double *argv = new double[10];   
!ec



After having compiled this program as 
!bc sys
c++ -o hw.exe hellowd.cpp
!ec
we can run the executable and obtain
!bc sys
Mortens-MacBook-Pro:cpp hjensen$ ./hw.exe 0.5
Hello, World! sin(0.5) =0.479426
!ec

If we do not write the value of $x$ on the command line we would get
!bc sys
Mortens-MacBook-Pro:cpp hjensen$ ./hw.exe 
Segmentation fault: 11
!ec

In this case, since reading from the command line with a number of arguments defined by the number of elements in the array _argv[]_, trying to access _argv[1]_ results in a segmentation fault. In the last case there is only one command line argument, the name of the executable program. It means that we have only the array element _argv[0]_. The element _argv[1]_ is not defined and we are trying to access something which is outside the memory slots reserved for _argv[]_. 

We can rewrite our "Hello World without the namespace usage":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/hellownonamespace.cpp". 

Namespaces provide a method for preventing name conflicts in large projects and 
symbols declared inside a namespace block are placed in a named scope that prevents them from being mistaken for identically-named symbols in other scopes.
Multiple namespace blocks with the same name are allowed. All declarations within those blocks are declared in the named scope.  This author likes to limit the usage of namespace to some few libraries, like the standard C library _csdtlib_. 


Here we present the C++ version without using namespace. 
!bc cpppro
// A comment line begins like this in C++ programs
// Standard ANSI-C++ include files
#include <cstdlib> // atof function 
#include <iostream>   // input and output
#include <cmath>      // math functions

int main (int argc, char* argv[])
{
  // convert the text argv[1] to double using atof:
  double r = atof(argv[1]);  // convert the text argv[1] to double
  double s = sin(r);
  // Note std::cout and std::endl
  std::cout << "Hello, World! sin(" << r << ") =" << s << std::endl;
  return 0;           // success execution of the program 
}
!ec

I personally tend to use _namespace_ for input and output as I feel it increases the readability of my codes. Thus, all examples from here and on will have a statement like 

!bc cppcod
using namespace std;
!ec





===== Brief summary =====

  * A C/C++ program begins with include statements of header files (libraries,intrinsic functions etc). This is similar to the _import_ statement in Python.
  * Functions which are used are normally defined at the top (details below)
  * The main program is declared as an integer, it returns 0 (everything correct) or 1 (something went wrong)
  * Standard `if`, `while` and `for` statements as in Java, Fortran, Python...
  * A C/C++ array begins by indexing at 0!
  * Array allocations are done by size, not by the final index value.If you allocate an array with 10 elements, you should index them from $0,1,\dots, 9$.
  * Initialize always an array before a computation.



=== From decimal to binary representation ===
Let us now write a program which translates an integer in the decimal representation to one in the binary representation. The mathematical formula for this is given by
!bt
\[
  a_n2^n+a_{n-1}2^{n-1}  +a_{n-2}2^{n-2}  +\dots +a_{0}2^{0}.
\]
!et

In binary notation we have thus $(417)_{10} =(110110001)_2$
since we have

!bt
\begin{align*}
(110100001)_2
&=1\times2^8+1\times 2^{7}+0\times 2^{6}+1\times 2^{5}+0\times 2^{4}+0\times 2^{3}\\
&+0\times 2^{2}+0\times 2^{2}+0\times 2^{1}+1\times 2^{0}.
\end{align*}
!et


To see this, we have performed the following divisions by 2

|-----------------------------------------------------------|
|            |             |                                |
|-----------------------------------------------------------|
| 417/2=208  | remainder 1 | coefficient of $2^{0}$ is 1    |
| 208/2=104  | remainder 0 | coefficient of $2^{1}$ is 0    |
| 104/2=52   | remainder 0 | coefficient of $2^{2}$ is 0    |
| 52/2=26    | remainder 0 | coefficient of $2^{3}$ is 0    |
| 26/2=13    | remainder 1 | coefficient of $2^{4}$ is 0    |
| 13/2= 6    | remainder 1 | coefficient of $2^{5}$ is 1    |
| 6/2= 3     | remainder 0 | coefficient of $2^{6}$ is 0    |
| 3/2= 1     | remainder 1 | coefficient of $2^{7}$ is 1    |
| 1/2= 0     | remainder 1 | coefficient of $2^{8}$ is 1    |
|-----------------------------------------------------------|


Let us now look at the "code which takes as input from the command line a number in the decimal representation and converts it into the binary representation":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/program2.cpp" 


!bc cppcod
#include <iostream>
#include <cmath>
#include <cstdio>
#include <cstdlib>
using namespace std;
int main (int argc, char* argv[])
{
  int terms[32]; // storage of a0, a1, etc, up to 32 bits
  int number = atoi(argv[1]); 
  // initialise the term a0, a1 etc
  for (int i=0; i < 32 ; i++) terms[i] = 0;
  for (int i=0; i < 32 ; i++){ 
    terms[i] = number%2;   // modulo division done by %
    number /= 2; 
  }
  // write out results
  cout << "Number of bytes used= " << sizeof(number) << endl;
  for (i=0; i < 32 ; i++){ 
    cout << " Term nr: " << i << "Value= " << terms[i];
    cout << endl;
  }
  return 0;  
}
!ec

To be noted here is the way we define a loop in C++. Our first encounter is

!bc cppcod
  for (i=0; i < 32 ; i++){ terms[i] = 0;}
!ec
The loop starts with the _for_ declaration, followed by a parenthesis hwere we declare the starting values (_i=0_) and the end value
(_i < 32_). What would have happened if we declared the endpoint as _i <=32_?  

This loop is just a oneliner that serves to initialize the array _terms[]_ to zero. Note the way we can write increment by one via _i++_.

Our next loop  
!bc cppcod
  for (int i=0; i < 32 ; i++){ 
    terms[i] = number%2;   // modulo division done by %
    number /= 2; 
  }
!ec
contains the actual algorithm for the translation of an integer in the decimal representation to an integer in the binary representation. We note the way we use the curly parentheses to mark where the content inside a loop starts and where it ends. It is useful to introduce some indentation (many text editors do this automatically for you when the file ends with _.cpp_) in order to increase readability.

The function _sizeof()_ tells how many bytes are used to store a given variable. An integer is by default defined in terms of four bytes or 32 bits. 

Our next example is a program that calculates the second derivative numerically  of a function (the exponential function here) and writes the result to a file declared by the user. The first thing to notice is declaration of the object _ofile_ which inherits all functionality from the _ofstream_ class. "This class":"http://www.cplusplus.com/reference/fstream/ofstream/" (to be discussed later below in connection with classes) overloads functions like writing to file, opening files, closing files etc. A similar class exists, the _ifstream_ class, for input variables. 
Adding the header file _fstream_ gives us access to the functionality of the _ofstream_ class. 
The _iomanip_ header files allows to format our output with functions like _setprecision_, _setw_ etc.

!bc cppcod
#include <iostream>
#include <cmath>
#include <fstream>
#include <iomanip>
// output file as global variable
ofstream ofile;

// Begin of main program

int main(int argc, char* argv[])
{
  char *outfilename;
  // Read in output file, abort if there are too few command-line arguments
  if( argc <= 3 ){
    cout << "Bad Usage: " << argv[0] <<
      " read also output file, number of integration points and the final x values  on same line, four variables in total" << std::endl;
    exit(1);
  }
  else{
    outfilename=argv[1];
  }
  //  opening a file for the program
  ofile.open(outfilename);
  // extracting number of mesh points
  int i = atoi(argv[2]);
  double x = atof(argv[3]);  // reading x-value
  double h = 1.0/((double) i); // setting up step size
  double Derivative = (exp(x+h)-2.*exp(x)+exp(x-h))/(h*h);
  double RelativeError = log10(fabs(Derivative-exp(x))/exp(x));
  ofile <<  setw(15) << setprecision(8) << "relative error=" << RelativeError << endl;
  ofile.close();  // close output file
  return 0;
}
!ec

We have in addition included some safety valves here. In case we have less than four variables on the command line, the program aborts.
After having read the name of the output file we open the file  and by default we can write to it via the statement
!bc cppcod
  ofile.open(outfilename);
!ec
and we close it at the end by
!bc cppcod
  ofile.close();
!ec

We have also defined how to write to file our result in a formatted way via the statement
!bc cppcod
  ofile <<  setw(15) << setprecision(8) << "relative error=" << RelativeError << endl;
!ec
where we reserve a field width of 15 characters and a precision of eight leading digits after the decimal point.

The above example represents our first simple case where we write our results to file. Before we proceed now, we need to say something more about pointers. 

===== Technical Matter in C/C++: Pointers =====

Variables are stored in the memory of a computer and each location in memory is defined by a unique address. How is memory management done?

The main memory contains the program data
* Cache memory contains a copy of the main memory data
* Cache is faster but consumes more space and power. It is normally assumed to be much faster than main memory
* Registers contain working data only
 * Modern CPUs perform most or all operations only on data in register
* Multiple Cache memories contain a copy of the main memory data
 * Cache items accessed by their address in main memory
 * L1 cache is the fastest but has the least capacity
 * L2, L3 provide intermediate performance/size tradeoffs
Loads and stores to memory can be as important as floating point operations when we measure performance.


* Most communication in a computer is carried out in chunks, blocks of bytes of data that move together
* In the memory hierarchy, data moves between memory and cache, and between different levels of cache, in groups called lines
 * Lines are typically 64-128 bytes, or 8-16 double precision words
 * Even if you do not use the data, it is moved and occupies space in the cache
* This performance feature is not captured in most programming languages

When we store variables in memory, each memory location is identified and referenced with an address (like a house number specifies where a particular family resides on a street).
Pointers play a central role in understanding memory management in C++. A pointer is just another name for an address and a pointer specifies where a value resides in the computer's memory. 

A pointer points to an address not to a data container of any kind! It is a variable (with its own address in memory) whose value is the address of some other memory location. C++ as programming language offers several operations that allow us to access say elements of an array in an efficient way by accessing data by their addresses.

Let us look at some simple example declarations. We define four variables and each of them is storeed in memory schematically as shown here (think of every box as a slot in memory of say 32 bits or more for each slot)
|-------------------------------|
| int a | int b | double c | int d | double e | 
|-------------------------------|
| 112 | -1 |3.14 | ? | ? |
|-------------------------------|

We have put questions marks for the values of the variables _d_ and _e_. 
In the program here we define _a_ and _b_ as integers and _c_ as a double. The variables _d_ and _e_ are declared as pointers. 
!bc cppcod
#include <iostream>
using namespace std;
//  Declare functions before main
int main(int argc, char *argv[])
{
  int a =112, b = -1;
  double c = 3.14;
  int *d = &a;
  double  *e = &c;

  cout << "Address of the integer variable a :" << &a <<endl;
  cout << "Value of the integer pointer variable d:" << d << endl;
  cout << "Value which pointer d is pointing at :" << *d << endl;
  cout << "Address of the double variable c :" << &c <<endl;
  cout << "Value of the integer pointer variable e:" << e << endl;
  cout << "Value which pointer e is pointing at :" << *e << endl;


  return 0;
} // End: function main()
!ec


Running this "program":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/program11.cpp" we get the following
!bc sys
Address of the integer variable a :0x7fff56966a7c
Value of the integer pointer variable d:0x7fff56966a7c
Value which pointer d is pointing at :112
Address of the double variable c :0x7fff56966a70
Value of the integer pointer variable e:0x7fff56966a70
Value which pointer e is pointing at :3.14
!ec
we see that the value of _d_ is the address of _a_ and it points to the value $112$ stored in the memory slot reserved for _a_. Similarly, _e_ is a pointer and gets as value the address of _c_, which is $0x7fff56966a70$ which points to the value of $3.14$. The operation
!bc cppcod
  int *d = &a;
!ec
is called dereferencing. We could alternatively have written
!bc cppcod
  int *d;
  d = &a;
!ec
where the latter means that _d_ gets as value the address of _a_. The print statement
!bc cppcod
  cout << "Value which pointer d is pointing at :" << *d << endl;
!ec
then prints the actual number it points at, that is the vaue of the variable _a_.

" Another pPointer example ":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/program7.cpp" is the following program

!bc cppcod
int main()
{
  int var;
  int *p;
  p = &var;
  var  = 421;
  printf("Address of integer variable var : %p\n",&var);
  printf("Its value: %d\n", var);
  printf("Value of integer pointer p : %p\n",p);
  printf("The value p points at :  %d\n",*p);
  printf("Address of the pointer p : %p\n",&p);
  return 0;
}
!ec
Dissecting it we have (now with the _printf_ function from standard C)

!bc cppcod
int main()
{
  int var;     // Define an integer variable var
  int *p;      // Define a pointer to an integer
  p = &var;    // Extract the address of var
  var = 421;   // Change content of var
  printf("Address of integer variable var : %p\n", &var);
  printf("Its value: %d\n", var);  // 421
  printf("Value of integer pointer p : %p\n", p);  // = &var
  // The content of the variable pointed to by p is *p
  printf("The value p points at :  %d\n", *p);
  // Address where the pointer is stored in memory
  printf("Address of the pointer p : %p\n", &p);
  return 0;
}
!ec
and running the code we get
!bc sys
Address of integer variable var : 0x7fff5cfe6ae8
Its value: 421
Value of integer pointer p : 0x7fff5cfe6ae8
The value p points at :  421
Address of the pointer p : 0x7fff5cfe6ae0
!ec
We see again that the value of the pointer _p_ is the address of the variable _var_. 

"The next pointer example":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/IntroProgramming/cpp/program8.cpp" deals with arrays and how to access array elements with pointer operations. 
!bc cppcod
int matr[2];    // Define integer array with two elements
int *p;         // Define pointer to integer
p = &matr[0];   // Point to the address of the first element in matr
matr[0] = 321;  // Change the first element
matr[1] = 322;  // Change the second element
printf("\nAddress of matrix element matr[1]: %p", &matr[0]);
printf("\nValue of the  matrix element  matr[1]; %d", matr[0]);
printf("\nAddress of matrix element matr[2]: %p", &matr[1]);
printf("\nValue of the matrix element  matr[2]: %d\n", matr[1]);
printf("\nValue of the pointer p: %p", p);
printf("\nThe value p points to: %d", *p);
printf("\nThe value that (p+1) points to  %d\n", *(p+1));
printf("\nAddress of pointer p : %p\n", &p);
!ec
Here we define an array with two elements. The pointer _p_ gets as value the address of the first element. The output of this program is

!bc sys
Address of the matrix element matr[1]: 0xbfffef70
Value of the  matrix element  matr[1]; 321
Address of the matrix element matr[2]: 0xbfffef74
Value of the matrix element  matr[2]: 322
Value of the pointer: 0xbfffef70
The value pointer points at: 321
The value that (pointer+1) points at:  322
Address of the pointer variable : 0xbfffef6c
!ec
We note that the operation
!bc cppcod
printf("\nThe value that (p+1) points to  %d\n", *(p+1));
!ec
allows us to print the address of the second array element. This is the way we can use pointers to access array elements.

Let us now discuss another subtle issue, that is transfer of data using call by value and call by reference, shown in the "program here":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program6.cpp".

!bc cppcod
#include <iostream>
using namespace std;
//  Declare functions before main
void func(int, int*);
int main(int argc, char *argv[]) 
{
  int a; 
  int *b;
  a = 10;
  b = new int[10];
  for(int i = 0; i < 10; i++) {
    b[i] = i;
    cout <<  b[i] << endl;
  }
  // the variable a is transferred by call by value. This means
  //  that the function func cannot change a in the calling function
  func( a,b);
  
  delete [] b ; 
  return 0;
} // End: function main()

void func( int x, int *y) 
{
  // a becomes locally x  and it can be changed locally
  x+=7;
  //  func gets the address of the first element of y (b)
  // it changes y[0] to 10 and when returning control to main
  // it changes also b[0]. Call by reference
  *y += 10;  //  *y = *y+10;
  //  explicit element 
  y[6] += 10;
  //   in this function y[0]  and y[6] have been changed and when returning 
  // control to main  this means that b[0] and b[6] are changed.  
  return;
} // End: function func()

!ec

There are several things to notice here. First, we have now declared a function _func_. This declaration is placed before the main function. If we don't do that the main function does not know how this function is to be used. The function takes as input an integer and an integer pointer defined by the asterix in
!bc cppcod
void func(int, int*);
!ec
This means that we transfer an address (in this case the address of the first element of the pointer _b_). This is called _call by reference_.
It means that the function _func_ can change the value of _b_ upon returning the instruction pointer to the main program (or calling function).
The other variable is transferred through what we label as  _call by value_. In this case the called function can change the value of _a_ locally but cannot change the value of this variable in the calling function.
The function _func_ func gets the address of the first element of y (b) and changes y[0] to 10 and when returning control to main
it changes also b[0]. This is done via
!bc cppcod
  *y += 10;  
!ec
This changes only the first element. To change another element, we would write (unless we use pointer operations)
!bc cppcod
  y[6] += 10;
!ec
which changes $\mathbf{y[6]}$  to $16$, since its orginal value was $6$, as defined in the main function. Using pointer operations we could write this as
!bc cppcod
  *(y+6) += 10;
!ec
and it produces the same result. It states that the value of the element which resides in $\mathbf{y[6]}$ is to be changed to $16$. 


C++ allows the programmer to use solely call by reference (note that call by reference is implemented as pointers). To see the difference between C and C++, consider the following simple examples.
In C we would write

!bc cppcod
   int n; n =8;
   func(&n); /* &n is a pointer to n */
   ....
   void func(int *i)
   {
     *i = 10; /* n is changed to 10 */
     ....
   }
!ec
whereas in C++ we would write
!bc cppcod
   int n; n =8;
   func(n); // just transfer n itself
   ....
   void func(int& i)
   {
     i = 10; // n is changed to 10
     ....
   }
!ec


The reason why we emphasize the difference between call by value and call
by reference is that it allows the programmer to avoid pitfalls
like unwanted changes of variables. However, many people feel that this
reduces the readability of the code.




Let us look at further Example codes in C++, with writing to file and "dynamic allocation for arrays":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program5.cpp"

!bc cppcod
#include <iostream>
#include <cmath>
#include <fstream>
#include <iomanip>
using namespace std; 

// output file as global variable

ofstream ofile;  

// Begin of main program   

int main(int argc, char* argv[])
{
  char *outfilename;
  // Read in output file, abort if there are too few command-line arguments
  if( argc <= 2 ){
    cout << "Bad Usage: " << argv[0] << 
      " read also output file and number of elements on same line" << endl;
    exit(1);
  }
  else{
    outfilename=argv[1];
  }

  //  opening a file for the program
  ofile.open(outfilename); 
  int i = atoi(argv[2]); 
 /* we can define it as 
  int *a;
  a = new int[i];
  or as
 */
  double *a = new double[i]; 
  cout << " bytes for i=" << sizeof(i) << endl;
  for (int j = 0; j < i; j++) {
    a[j] = j*exp(2.0);
    // ofile instead of cout
    ofile << setw(15) << setprecision(8) << "a=" << a[j] << endl;
  }
  delete [] a; // free memory
  ofile.close();  // close output file
  return 0;
}

!ec

Here we read from the command line the number of elements _i_ via
!bc cppcod
  int i = atoi(argv[2]); 
!ec
and allocate memory dynamically by declaring a pointer array (a vector here) _a_ using
!bc cppcod
  double *a = new double[i];
!ec
Using dynamic memory allocation we actually allow  memory to be more flexibly and explicitly managed.
When the memory is no longer needed, the pointer is passed to free which deallocates the memory so that it can be used for other purposes. This is done by the _delete_ statement
!bc cppcod
  delete [] a; // free memory
!ec

In the loop
!bc cppcod
  for (int j = 0; j < i; j++) {
    a[j] = j*exp(2.0);
    // ofile instead of cout
    ofile << setw(15) << setprecision(8) << "a=" << a[j] << endl;
  }
!ec
we assign a specific value to each array element and print to file. 

If we wish to time our function, the following "program":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp" gives a typical example. 
!bc cppcod
#include <cstdlib>
#include <iostream>
#include <cmath>
#include <iomanip> 
#include "time.h"   // Not the use time.h

using namespace std; // note use of namespace                                       
int main (int argc, char* argv[])
{
  int i = atoi(argv[1]); 
  double *a, *b, *c;
  a = new double[i]; 
  b = new double[i]; 
  c = new double[i]; 

  clock_t start, finish;
  start = clock();
  for (int j = 0; j < i; j++) {
    a[j] = cos(j*1.0);
    b[j] = sin(j+3.0);
    c[j] = 0.0;
  }
  for (int j = 0; j < i; j++) {
    c[j] = a[j]+b[j];
  }
  finish = clock();
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
  cout << setiosflags(ios::showpoint | ios::uppercase);
  cout << setprecision(10) << setw(20) << "Time used  for vector addition=" << timeused  << endl;
  delete [] a;
  delete [] b;
  delete [] c;
  return 0;           /* success execution of the program */
}
!ec
When timing the program, you should carefully plan what to time. Here we calculate the time difference from the point where we start filling in the three arrays _a_, _b_ and _c_ defining the starting time as
!bc cppcod
  clock_t start, finish;
  start = clock();
  for (int j = 0; j < i; j++) {
!ec
The final time is when all operations we are interested in are concluded, namely at
!bc cppcod
  for (int j = 0; j < i; j++) {
    c[j] = a[j]+b[j];
  }
  finish = clock();
!ec
The time difference from start to end, with its granularity is defined as
!bc cppcod
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
!ec

When timing a program you should pay attention to the following:
o Timers are not infinitely accurate
o All clocks have a granularity, the minimum time that they can measure
o The error in a time measurement, even if everything is perfect, may be the size of this granularity (sometimes called a clock tick)
o Always know what your clock granularity is
o Ensure that your measurement is for a long enough duration (say 100 times the _tick_)

What happens when the code is executed? The assumption is that the code is ready to
execute. But
o Code may still be on disk, and not even read into memory.
o Data may be in slow memory rather than fast (which may be wrong or right for what you are measuring)
o Multiple tests often necessary to ensure that cold start effects are not present
o Special effort often required to ensure data in the intended part of the memory hierarchy.

You should thus think of a numerical calculation as an experiment. To provide benchmark times you should thus run the timing measurement several times and then take the average over a series of simulations. 


===== Using _strings_ instead of characters =====

Till now we have used character variables when declaring for example filenames for output or input files. C++ offers a compact and flexible way of dealing with text strings through the _string_ class. In the program below we wish for example to define several output files for our calculations byapending  to a basename read in on the command line various endings. These endings can then be used to recognize a specific calculation.
Here we read the basic name of an ouput file and add to it the actual exponent used in a calculation by appending it to the file name. We show only the relevant parts 
!bc cppcod
#include <iostream>
#include <fstream>
#include <iomanip>
#include <cmath>
#include <string>
// use namespace for output and input
using namespace std;

// object for output files
ofstream ofile;


// Begin main program
int main(int argc, char *argv[]){
  int exponent; 
    string filename;
    // We read also the basic name for the output file and the highest power of 10^n we want
    if( argc <= 1 ){
          cout << "Bad Usage: " << argv[0] <<
              " read also file name on same line and max power 10^n" << endl;
          exit(1);
    }
        else{
        filename = argv[1]; // first command line argument after name of program
        exponent = atoi(argv[2]);
    }
    // Loop over powers of 10
    for (int i = 1; i <= exponent; i++){
      int  n = (int) pow(10.0,i);
      // Declare new file name
      string fileout = filename;
      // Convert the power 10^i to a string
      string argument = to_string(i);
      // Final filename as filename-i- by appending the power of 10
      fileout.append(argument);
      ofile.open(fileout);
      ofile << setiosflags(ios::showpoint | ios::uppercase);
      //   Do something 
      ofile.close();  // close output file wth given ending
    }
    return 0;
}
!ec

Instead of our earlier definition
!bc cppcod
  char *outfilename;
!ec
we define now the same output file via the _string_ statement, inheriting thus all functionality of the _string_ class by writing
!bc cppcod
    string filename;
!ec
In the statement
!bc cppcod
    filename = argv[1]; 
!ec
the variable _filename_ gets the name of file we declared on the command line.
A new file for the specific calculation is then established via
!bc cppcod
      // Declare new file name
      string fileout = filename;
      // Convert the power 10^i to a string
      string argument = to_string(i);
      // Final filename as filename-i- by appending the power of 10
      fileout.append(argument);
      ofile.open(fileout);  // then open
!ec
We recommend using the _string_ class, it gives ou much more flexibility in handling strings. 

===== More information will be added =====


=====     Optimization and profiling =====

Till now we have not paid much attention to speed and possible optimization possibilities
inherent in the various compilers. We have compiled and linked as
!bc cppcod
c++  -c  mycode.cpp
c++  -o  mycode.exe  mycode.o
!ec
For Fortran replace with for example _gfortran_ or _ifort_.
This is what we call a flat compiler option and should be used when we develop the code.
It produces normally a very large and slow code when translated to machine instructions.
We use this option for debugging and for establishing the correct program output because
every operation is done precisely as the user specified it.

It is instructive to look up the compiler manual for further instructions by writing
!bc cppcod
man c++
!ec

We have additional compiler options for optimization. These may include procedure inlining where 
performance may be improved, moving constants inside loops outside the loop, 
identify potential parallelism, include automatic vectorization or replace a division with a reciprocal
and a multiplication if this speeds up the code.
!bc cppcod
c++  -O3 -c  mycode.cpp
c++  -O3 -o  mycode.exe  mycode.o
!ec
This (other options are -O2 or -Ofast) is the recommended option. 


It is also useful to profile your program under the development stage.
You would then compile with 
!bc cppcod
c++  -pg -O3 -c  mycode.cpp
c++  -pg -O3 -o  mycode.exe  mycode.o
!ec
After you have run the code you can obtain the profiling information via
!bc cppcod
gprof mycode.exe >  ProfileOutput
!ec
When you have profiled properly your code, you must take out this option as it 
slows down performance.
For memory tests use "valgrind":"http://www.valgrind.org". An excellent environment for all these aspects, and much  more, is  Qt creator.


Adding debugging options is a very useful alternative under the development stage of a program.
You would then compile with 
!bc cppcod
c++  -g -O0 -c  mycode.cpp
c++  -g -O0 -o  mycode.exe  mycode.o
!ec
This option generates debugging information allowing you to trace for example if an array is properly allocated. Some compilers work best with the no optimization option _-O0_. 


Depending on the compiler, one can add flags which generate code that catches integer overflow errors. 
The flag _-ftrapv_ does this for the CLANG compiler on OS X operating systems.   

In general, irrespective of compiler options, it is useful to
* avoid if tests or call to functions inside loops, if possible. 
* avoid multiplication with constants inside loops if possible
Here is an example of a part of a program where specific operations lead to a slower code
!bc cppcod
k = n-1;
for (i = 0; i < n; i++){
    a[i] = b[i] +c*d;
    e = g[k];
}
!ec
A better code is
!bc cppcod
temp = c*d;
for (i = 0; i < n; i++){
    a[i] = b[i] + temp;
}
e = g[n-1];
!ec
Here we avoid a repeated multiplication inside a loop. 
Most compilers, depending on compiler flags, identify and optimize such bottlenecks on their own, without requiring any particular action by the programmer. However, it is always useful to single out and avoid code examples like the first one discussed here.


===== Vectorization and the basic idea behind parallel computing =====

Present CPUs are highly parallel processors with varying levels of parallelism. The typical situation can be described via the following three statements.
* Pursuit of shorter computation time and larger simulation size gives rise to parallel computing.
* Multiple processors are involved to solve a global problem.
* The essence is to divide the entire computation evenly among collaborative processors.  Divide and conquer.

Before we proceed with a more detailed discussion of topics like vectorization and parallelization, we need to remind ourselves about some basic features of different hardware models. We have


* Conventional single-processor computers are named SISD (single-instruction-single-data) machines.
* SIMD (single-instruction-multiple-data) machines incorporate the idea of parallel processing, using a large number of processing units to execute the same instruction on different data.
* Modern parallel computers are so-called MIMD (multiple-instruction-multiple-data) machines and can execute different instruction streams in parallel on different data.


===== What is vectorization? ===== 

Vectorization is a special
case of _Single Instructions Multiple Data_ (SIMD) to denote a single
instruction stream capable of operating on multiple data elements in
parallel. 
We can think of vectorization as the unrolling of loops accompanied with SIMD instructions.

Vectorization is the process of converting an algorithm that performs scalar operations
(typically one operation at the time) to vector operations where a single operation can refer to many simultaneous operations.
Consider the following example
!bc cppcod
for (i = 0; i < n; i++){
    a[i] = b[i] + c[i];
}
!ec
If the code is not vectorized, the compiler will simply start with the first element and 
then perform subsequent additions operating on one address in memory at the time. 


A SIMD instruction can operate  on multiple data elements in one single instruction.
It uses the so-called 128-bit SIMD floating-point register. 
In this sense,vectorization adds some form of parallelism since one instruction is applied  
to many parts of say a vector.

The number of elements which can be operated on in parallel
range from four single-precision floating point data elements in so-called 
Streaming SIMD Extensions and two double-precision floating-point data
elements in Streaming SIMD Extensions 2 to sixteen byte operations in
a 128-bit register in Streaming SIMD Extensions 2. Thus, vector-length
ranges from 2 to 16, depending on the instruction extensions used and
on the data type. 


We start with the simple scalar operations given by
!bc cppcod
for (i = 0; i < n; i++){
    a[i] = b[i] + c[i];
}
!ec
If the code is not vectorized  and we have a 128-bit register to store a 32 bits floating point number,
it means that we have $3\times 32$ bits that are not used. For the first element we have


|-------------------------------|
| 0 | 1 | 2 | 3                 | 
|-------------------------------|
| a[0]= | not used | not used| not used|
|-------------------------------|
| b[0]+ | not used | not used| not used|
|-------------------------------|
| c[0] | not used | not used| not used|
|-------------------------------|

We have thus unused space in our SIMD registers. These registers could hold three additional integers.



If we vectorize the code, we can perform, with a 128-bit register four simultaneous operations, that is
we have
!bc cppcod
for (i = 0; i < n; i+=4){
    a[i] = b[i] + c[i];
    a[i+1] = b[i+1] + c[i+1];
    a[i+2] = b[i+2] + c[i+2];
    a[i+3] = b[i+3] + c[i+3];
}
!ec
displayed here as

|-------------------------------|
| 0 | 1 | 2 | 3                 | 
|-------------------------------|
|  a[0]= | a[1]= | a[2]=| a[3]= |
|-------------------------------|
|  b[0]+ | b[1]+ | b[2]+| b[3]+ |
|-------------------------------|
| c[0]| c[1] | c[2] | c[3]      | 
|-------------------------------|
Four additions are now done in a single step.


===== "A simple test case with and without vectorization":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp" =====
We implement these operations in a simple c++ program as 

!bc cppcode
#include <cstdlib>
#include <iostream>
#include <cmath>
#include <iomanip>
#include "time.h" 

using namespace std; // note use of namespace                                       
int main (int argc, char* argv[])
{
  int i = atoi(argv[1]); 
  double *a, *b, *c;
  a = new double[i]; 
  b = new double[i]; 
  c = new double[i]; 
  for (int j = 0; j < i; j++) {
    a[j] = 0.0;
    b[j] = cos(j*1.0);
    c[j] = sin(j*3.0);
  }
  clock_t start, finish;
  start = clock();
  for (int j = 0; j < i; j++) {
    a[j] = b[j]+b[j]*c[j];
  }
  finish = clock();
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
  cout << setiosflags(ios::showpoint | ios::uppercase);
  cout << setprecision(10) << setw(20) << "Time used  for vector addition and multiplication=" << timeused  << endl;
  delete [] a;
  delete [] b;
  delete [] c;
  return 0;     
}
!ec



We can compile and link without vectorization
!bc cppcod
c++ -o novec.x vecexample.cpp
!ec
vand with vectorization (and additional optimizations)
!bc cppcod
c++ -O3 -o  vec.x vecexample.cpp 
!ec
The speedup depends on the size of the vectors. In the example here we have run with $10^7$ elements.
The example here was run on a PC with ubuntu 14.04 as operating system and an Intel i7-4790 CPU running at 3.60 GHz. 
!bc cppcod 
Compphys:~ hjensen$ ./vec.x 10000000
Time used  for vector addition = 0.0100000
Compphys:~ hjensen$ ./novec.x 10000000
Time used  for vector addition = 0.03000000000
!ec
This particular C++ compiler speeds up the above loop operations with a factor of 3. 
Performing the same operations for $10^8$ elements results only in a factor $1.4$.
The result will however vary from compiler to compiler. In general however, with optimization flags like $-O3$ or $-Ofast$, we gain a considerable speedup if our code can be vectorized. Many of these operations can be done automatically by your compiler. These automatic or near automatic compiler techniques improve performance considerably. 


Not all loops can be vectorized, as discussed in "Intel's guide to vectorization":"https://software.intel.com/en-us/articles/a-guide-to-auto-vectorization-with-intel-c-compilers"

An important criteria is that the loop counter $n$ is known at the entry of the loop.
!bc cppcod
  for (int j = 0; j < n; j++) {
    a[j] = cos(j*1.0);
  }
!ec
The variable $n$ does need to be known at compile time. However, this variable must stay the same for the entire duration of the loop. It implies that an exit statement inside the loop cannot be data dependent.


An exit statement should in general be avoided. 
If the exit statement contains data-dependent conditions, the loop cannot be vectorized. 
The following is an example of a non-vectorizable loop
!bc cppcod
  for (int j = 0; j < n; j++) {
    a[j] = cos(j*1.0);
    if (a[j] < 0 ) break;
  }
!ec
Avoid loop termination conditions and opt for a single entry loop variable $n$. The lower and upper bounds have to be kept fixed within the loop. 

SIMD instructions perform the same type of operations multiple times. 
A _switch_ statement leads thus to a non-vectorizable loop since different statemens cannot branch.
The following code can however be vectorized since the _if_ statement is implemented as a masked assignment.
!bc cppcod
  for (int j = 0; j < n; j++) {
    double x  = cos(j*1.0);
    if (x > 0 ) {
       a[j] =  x*sin(j*2.0); 
    }
    else {
       a[j] = 0.0;
    }
  }
!ec
These operations can be performed for all data elements but only those elements which the mask evaluates as true are stored. In general, one should avoid branches such as _switch_, _go to_, or _return_ statements or _if_ constructs that cannot be treated as masked assignments. 




Only the innermost loop of the following example is vectorized
!bc cppcod
  for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
           a[i][j] += b[i][j];
      }  
  }
!ec
The exception is if an original outer loop is transformed into an inner loop as the result of compiler optimizations.



Calls to programmer defined functions ruin vectorization. However, calls to intrinsic functions like
$\sin{x}$, $\cos{x}$, $\exp{x}$ etc are allowed since they are normally efficiently vectorized. 
The following example is fully vectorizable
!bc cppcod
  for (int i = 0; i < n; i++) {
      a[i] = log10(i)*cos(i);
  }
!ec
Similarly, _inline_ functions defined by the programmer, allow for vectorization since the function statements are glued into the actual place where the function is called. 



One has to keep in mind that vectorization changes the order of operations inside a loop. A so-called
read-after-write statement with an explicit flow dependency cannot be vectorized. The following code
!bc cppcod
  double b = 15.;
  for (int i = 1; i < n; i++) {
      a[i] = a[i-1] + b;
  }
!ec
is an example of flow dependency and results in wrong numerical results if vectorized. For a scalar operation, the value $a[i-1]$ computed during the iteration is loaded into the right-hand side and the results are fine. In vector mode however, with a vector length of four, the values $a[0]$, $a[1]$, $a[2]$ and $a[3]$ from the previous loop will be loaded into the right-hand side and produce wrong results. That is, we have
!bc cppcod
   a[1] = a[0] + b;
   a[2] = a[1] + b;
   a[3] = a[2] + b;
   a[4] = a[3] + b;
!ec
and if the two first iterations are  executed at the same by the SIMD instruction, the value of say $a[1]$ could be used by the second iteration before it has been calculated by the first iteration, leading thereby to wrong results.


On the other hand,  a so-called 
write-after-read statement can be vectorized. The following code
!bc cppcod
  double b = 15.;
  for (int i = 1; i < n; i++) {
      a[i-1] = a[i] + b;
  }
!ec
is an example of flow dependency that can be vectorized since no iteration with a higher value of $i$
can complete before an iteration with a lower value of $i$. However, such code leads to problems with parallelization.



For C++ programmers  it is also worth keeping in mind that an array notation is preferred to the more compact use of pointers to access array elements. The compiler can often not tell if it is safe to vectorize the code. 

When dealing with arrays, you should also avoid memory stride, since this slows down considerably vectorization. When you access array element, write for example the inner loop to vectorize using unit stride, that is, access successively the next array element in memory, as shown here
!bc cppcod
  for (int i = 0; i < n; i++) {
      for (int j = 0; j < n; j++) {
           a[i][j] += b[i][j];
      }  
  }
!ec


We can compile and link without vectorization using the clang c++ (on OSX for example) compiler
!bc cppcod
clang -o novec.x vecexample.cpp
!ec
and with vectorization (and additional optimizations)
!bc cppcod
clang++ -O3 -Rpass=loop-vectorize -o  vec.x vecexample.cpp 
!ec
The speedup depends on the size of the vectors. In the example here we have run with $10^7$ elements.
The example here was run on an IMac17.1 with OSX El Capitan (10.11.4) as operating system and an Intel i5 3.3 GHz CPU.  
!bc cppcod 
Compphys:~ hjensen$ ./vec.x 10000000
Time used  for norm computation=0.04720500000
Compphys:~ hjensen$ ./novec.x 10000000
Time used  for norm computation=0.03311700000
!ec
This particular C++ compiler speeds up the above loop operations with a factor of 1.5 
Performing the same operations for $10^9$ elements results in a smaller speedup since reading from main memory is required. The non-vectorized code is seemingly faster. 
!bc cppcod 
Compphys:~ hjensen$ ./vec.x 1000000000
Time used  for norm computation=58.41391100
Compphys:~ hjensen$ ./novec.x 1000000000
Time used  for norm computation=46.51295300
!ec
We will discuss these issues below.

We can compile and link without vectorization with clang compiler
!bc cppcod
clang++ -o -fno-vectorize novec.x vecexample.cpp
!ec
and with vectorization
!bc cppcod
clang++ -O3 -Rpass=loop-vectorize -o  vec.x vecexample.cpp 
!ec
We can also add vectorization analysis, see for example
!bc cppcod
clang++ -O3 -Rpass-analysis=loop-vectorize -o  vec.x vecexample.cpp 
!ec
or figure out if vectorization was missed
!bc cppcod
clang++ -O3 -Rpass-missed=loop-vectorize -o  vec.x vecexample.cpp 
!ec



=====  Measuring performance =====

How do we measure erformance? What is wrong with this code to time a loop?
!bc
  clock_t start, finish;
  start = clock();
  for (int j = 0; j < i; j++) {
    a[j] = b[j]+b[j]*c[j];
  }
  finish = clock();
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
!ec


=====  Problems with measuring time =====
o Timers are not infinitely accurate
o All clocks have a granularity, the minimum time that they can measure
o The error in a time measurement, even if everything is perfect, may be the size of this granularity (sometimes called a clock tick)
o Always know what your clock granularity is
o Ensure that your measurement is for a long enough duration (say 100 times the _tick_)


=====  Problems with cold start =====

What happens when the code is executed? The assumption is that the code is ready to
execute. But
o Code may still be on disk, and not even read into memory.
o Data may be in slow memory rather than fast (which may be wrong or right for what you are measuring)
o Multiple tests often necessary to ensure that cold start effects are not present
o Special effort often required to ensure data in the intended part of the memory hierarchy.


=====  Problems with smart compilers =====

o If the result of the computation is not used, the compiler may eliminate the code
o Performance will look impossibly fantastic
o Even worse, eliminate some of the code so the performance looks plausible
o Ensure that the results are (or may be) used.


=====  Problems with interference =====
o Other activities are sharing your processor
  * Operating system, system demons, other users
  *  Some parts of the hardware do not always perform with exactly the same performance
o Make multiple tests and report
o Easy choices include
 *  Average tests represent what users might observe over time



=====  Problems with measuring performance  =====
o Accurate, reproducible performance measurement is hard
o Think carefully about your experiment:
o What is it, precisely, that you want to measure
o How representative is your test to the situation that you are trying to measure?


===== Thomas algorithm for tridiagonal linear algebra equations =====
!bt
\[
\left( \begin{array}{ccccc}
        b_0 & c_0 &        &         &         \\
	a_0 &  b_1 &  c_1    &         &         \\
	   &    & \ddots  &         &         \\
	      &	    & a_{m-3} & b_{m-2} & c_{m-2} \\
	         &    &         & a_{m-2} & b_{m-1}
   \end{array} \right)
\left( \begin{array}{c}
       x_0     \\
       x_1     \\
       \vdots  \\
       x_{m-2} \\
       x_{m-1}
   \end{array} \right)=\left( \begin{array}{c}
       f_0     \\
       f_1     \\
       \vdots  \\
       f_{m-2} \\
       f_{m-1} \\
   \end{array} \right)
\]
!et

The first step is to multiply the first row by $a_0/b_0$ and subtract it from the second row.  This is known as the forward substitution step. We obtain then
!bt
\[
	a_i = 0,
\]
!et

!bt
\[                                 
	b_i = b_i - \frac{a_{i-1}}{b_{i-1}}c_{i-1},
\]
!et
and
!bt
\[
	f_i = f_i - \frac{a_{i-1}}{b_{i-1}}f_{i-1}.
\]
!et
At this point the simplified equation, with only an upper triangular matrix takes the form
!bt
\[
\left( \begin{array}{ccccc}
    b_0 & c_0 &        &         &         \\
       & b_1 &  c_1    &         &         \\
          &    & \ddots &         &         \\
	     &     &        & b_{m-2} & c_{m-2} \\
	        &    &        &         & b_{m-1}
   \end{array} \right)\left( \begin{array}{c}
       x_0     \\
       x_1     \\
       \vdots  \\
       x_{m-2} \\
       x_{m-1}
   \end{array} \right)=\left( \begin{array}{c}
       f_0     \\
       f_1     \\
       \vdots  \\
       f_{m-2} \\
       f_{m-1} \\
   \end{array} \right)
\]
!et

The next step is  the backward substitution step.  The last row is multiplied by $c_{N-3}/b_{N-2}$ and subtracted from the second to last row, thus eliminating $c_{N-3}$ from the last row.  The general backward substitution procedure is 
!bt
\[
	c_i = 0, 
\]
!et
and 
!bt
\[
	f_{i-1} = f_{i-1} - \frac{c_{i-1}}{b_i}f_i
\]
!et
All that remains to be computed is the solution, which is the very straight forward process of
!bt
\[
x_i = \frac{f_i}{b_i}
\]
!et

|-------------------------------------------------------------------------------------------|
|  Operation     | Floating Point | 
|-------------------------------------------------------------------------------------------|
| Memory Reads   |    $14(N-2)$   |
| Memory Writes  |     $4(N-2)$   |
| Subtractions   |     $3(N-2)$   |
| Multiplications |     $3(N-2)$  |
| Divisions       |     $4(N-2)$  |
|-------------------------------------------------------------------------------------------|


!bc cppcod
// Forward substitution    
// Note that we can simplify by precalculating a[i-1]/b[i-1]
  for (int i=1; i < n; i++) {
     b[i] = b[i] - (a[i-1]*c[i-1])/b[i-1];
     f[i] = g[i] - (a[i-1]*f[i-1])/b[i-1];
  }
  x[n-1] = f[n-1] / b[n-1];
  // Backwards substitution                                                           
  for (int i = n-2; i >= 0; i--) {
     f[i] = f[i] - c[i]*f[i+1]/b[i+1];
     x[i] = f[i]/b[i];
  }
!ec

=====  "The specialized Thomas algorithm (Project 1)":"https://github.com/CompPhysics/ComputationalPhysics/blob/master/doc/Projects/2016/Project1/Examples/TridiagonalTiming.cpp"  =====


|-------------------------------------------------------------------------------------------|
|  Operation     | Floating Point | 
|-------------------------------------------------------------------------------------------|
| Memory Reads   |    $6(N-2)$   |
| Memory Writes  |     $2(N-2)$   |
| Additions   |     $2(N-2)$   |
| Divisions       |     $2(N-2)$  |
|-------------------------------------------------------------------------------------------|


!bc cppcod
      // Forward substitution cannot be vectorized
      for (int i = 2; i < n; i++) b[i] = b[i] + b[i-1]/d[i-1];
      // Backward substitution  cannot be vectorized
      solution[n-1] = b[n-1]/d[n-1];
      for (int i = n-2; i > 0; i--) solution[i] = (b[i]+solution[i+1])/d[i];
!ec

===== "Example: Transpose of a matrix":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program8.cpp" =====

!bc cppcode
#include <cstdlib>
#include <iostream>
#include <cmath>
#include <iomanip>
#include "time.h"

using namespace std; // note use of namespace
int main (int argc, char* argv[])
{
  // read in dimension of square matrix
  int n = atoi(argv[1]);
  double **A, **B;
  // Allocate space for the two matrices
  A = new double*[n]; B = new double*[n];
  for (int i = 0; i < n; i++){
    A[i] = new double[n];
    B[i] = new double[n];
  }
  // Set up values for matrix A
  for (int i = 0; i < n; i++){
    for (int j = 0; j < n; j++) {
      A[i][j] =  cos(i*1.0)*sin(j*3.0);
    }
  }
  clock_t start, finish;
  start = clock();
  // Then compute the transpose
  for (int i = 0; i < n; i++){
    for (int j = 0; j < n; j++) {
      B[i][j]= A[j][i];
    }
  }

  finish = clock();
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
  cout << setiosflags(ios::showpoint | ios::uppercase);
  cout << setprecision(10) << setw(20) << "Time used  for setting up transpose of matrix=" << timeused  << endl;

  // Free up space
  for (int i = 0; i < n; i++){
    delete[] A[i];
    delete[] B[i];
  }
  delete[] A;
  delete[] B;
  return 0;
}

!ec



=====  "Matrix-matrix multiplication":"https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program9.cpp" =====
This the matrix-matrix multiplication code with plain c++ memory allocation. It computes at the end the Frobenius norm.

!bc
#include <cstdlib>
#include <iostream>
#include <cmath>
#include <iomanip>
#include "time.h"

using namespace std; // note use of namespace
int main (int argc, char* argv[])
{
  // read in dimension of square matrix
  int n = atoi(argv[1]);
  double s = 1.0/sqrt( (double) n);
  double **A, **B, **C;
  // Start timing
  clock_t start, finish;
  start = clock();
  // Allocate space for the two matrices
  A = new double*[n]; B = new double*[n]; C = new double*[n];
  for (int i = 0; i < n; i++){
    A[i] = new double[n];
    B[i] = new double[n];
    C[i] = new double[n];
  }
  // Set up values for matrix A and B and zero matrix C
  for (int i = 0; i < n; i++){
    for (int j = 0; j < n; j++) {
      double angle = 2.0*M_PI*i*j/ (( double ) n);
      A[i][j] = s * ( sin ( angle ) + cos ( angle ) );
      B[j][i] =  A[i][j];
    }
  }
  // Then perform the matrix-matrix multiplication
  for (int i = 0; i < n; i++){
    for (int j = 0; j < n; j++) {
      double sum = 0.0;
       for (int k = 0; k < n; k++) {
           sum += B[i][k]*A[k][j];
       }
       C[i][j] = sum;
    }
  }
  // Compute now the Frobenius norm
  double Fsum = 0.0;
  for (int i = 0; i < n; i++){
    for (int j = 0; j < n; j++) {
      Fsum += C[i][j]*C[i][j];
    }
  }
  Fsum = sqrt(Fsum);
  finish = clock();
  double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );
  cout << setiosflags(ios::showpoint | ios::uppercase);
  cout << setprecision(10) << setw(20) << "Time used  for matrix-matrix multiplication=" << timeused  << endl;
  cout << "  Frobenius norm  = " << Fsum << endl;
  // Free up space
  for (int i = 0; i < n; i++){
    delete[] A[i];
    delete[] B[i];
    delete[] C[i];
  }
  delete[] A;
  delete[] B;
  delete[] C;
  return 0;
}
!ec


=====  How do we define speedup? Simplest form =====

* Speedup(code,sys,p) = $T_b/T_p$
* Speedup measures the ratio of performance between two objects
* Versions of same code, with different number of processors
* Serial and vector versions
* Try different programing languages, C++ and Fortran
* Two algorithms computing the _same_ result 

The key is choosing the correct baseline for comparison
* For our serial vs. vectorization examples, using compiler-provided vectorization, the baseline is simple; the same code, with vectorization turned off
*  For parallel applications, this is much harder:
  * Choice of algorithm, decomposition, performance of baseline case etc.








